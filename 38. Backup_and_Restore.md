Here's a clean and complete version of the `README.md` section with the detailed instructions for restoring the etcd snapshot and updating the configuration:

```markdown
# Restoring an etcd Snapshot

### Step 1: Restore the Snapshot
Run the following command to restore the etcd snapshot to a new directory:

```bash
root@controlplane:~# ETCDCTL_API=3 etcdctl --data-dir /var/lib/etcd-from-backup \
snapshot restore /opt/snapshot-pre-boot.db
```

**Sample Output:**
```
2022-03-25 09:19:27.175043 I | mvcc: restore compact to 2552
2022-03-25 09:19:27.266709 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32
```

**Note:**  
In this case, we are restoring the snapshot to a different directory (`/var/lib/etcd-from-backup`) but on the same server where the backup was taken (the controlplane node). Therefore, the only required option for the restore command is the `--data-dir`.

---

### Step 2: Update the etcd Configuration

Now that we have restored the etcd snapshot to a new directory on the controlplane (`/var/lib/etcd-from-backup`), we need to update the etcd static pod configuration file located at `/etc/kubernetes/manifests/etcd.yaml`.

Modify the `hostPath` for the volume named `etcd-data` from the old directory (`/var/lib/etcd`) to the new directory (`/var/lib/etcd-from-backup`):

```yaml
volumes:
- hostPath:
    path: /var/lib/etcd-from-backup
    type: DirectoryOrCreate
  name: etcd-data
```

With this change, `/var/lib/etcd` inside the container will point to `/var/lib/etcd-from-backup` on the controlplane.

---

### Step 3: Automatic Pod Recreation

When the `/etc/kubernetes/manifests/etcd.yaml` file is updated, the etcd pod will be automatically re-created, as it is a static pod managed by Kubernetes.

---

### Additional Notes

1. **Pod Restarts:**  
   Since the etcd pod configuration has changed, it will restart automatically. The `kube-controller-manager` and `kube-scheduler` pods will also restart. This process typically takes 1-2 minutes.  

   You can monitor the etcd pod's status using the following command:
   ```bash
   watch "crictl ps | grep etcd"
   ```

2. **Manual Restart (If Needed):**  
   If the etcd pod does not reach a `Ready 1/1` state, you can manually restart it:
   ```bash
   kubectl delete pod -n kube-system etcd-controlplane
   ```
   Wait for 1 minute and check the pod's status again.

3. **Volume Mount Path:**  
   If you update the `--data-dir` option in the etcd YAML file to `/var/lib/etcd-from-backup`, ensure that the `volumeMounts` for `etcd-data` are updated accordingly, with the `mountPath` pointing to `/var/lib/etcd-from-backup`.

This method ensures that etcd uses the restored snapshot data when the etcd pod is recreated. No additional changes are necessary.
```